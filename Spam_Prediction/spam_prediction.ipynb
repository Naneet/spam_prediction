{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e275ca-10c5-48ac-a169-e926d5e2e547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2add2a8fb30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libs\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# setting a random seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd28a87-a4ea-4a25-a2a2-50173a3c1f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "931f6582-4776-420e-bd74-0a2c25d74616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       Go until jurong point, crazy.. Available only ...\n",
       " 1                           Ok lar... Joking wif u oni...\n",
       " 2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       " 3       U dun say so early hor... U c already then say...\n",
       " 4       Nah I don't think he goes to usf, he lives aro...\n",
       "                               ...                        \n",
       " 5567    This is the 2nd time we have tried 2 contact u...\n",
       " 5568                Will ÃŒ_ b going to esplanade fr home?\n",
       " 5569    Pity, * was in mood for that. So...any other s...\n",
       " 5570    The guy did some bitching but I acted like i'd...\n",
       " 5571                           Rofl. Its true to its name\n",
       " Name: v2, Length: 5572, dtype: object,\n",
       " 0        ham\n",
       " 1        ham\n",
       " 2       spam\n",
       " 3        ham\n",
       " 4        ham\n",
       "         ... \n",
       " 5567    spam\n",
       " 5568     ham\n",
       " 5569     ham\n",
       " 5570     ham\n",
       " 5571     ham\n",
       " Name: v1, Length: 5572, dtype: object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing dataset\n",
    "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# assigning dataset and labels\n",
    "X = df[\"v2\"]\n",
    "y = df[\"v1\"]\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aaa9683-bada-4e48-8984-cae04922f69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 1115, 5572)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting data for training and testing the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Checking the split\n",
    "len(X_train), len(X_test), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "446c45bc-65ec-486f-8d8e-55307e8b1b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the data and label into list\n",
    "X_train = X_train.to_list()\n",
    "X_test = X_test.to_list()\n",
    "y_train = y_train.to_list()\n",
    "y_test = y_test.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5bc59b0-af44-41c2-a40b-45e8c8fbd9d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mapping each word in vocab unique intergers\n",
    "word_to_ix = {}\n",
    "for sentence in X_train + X_test:\n",
    "    sent = sentence.split()\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6989d0f2-10ff-4f8b-8361-e5afc3109859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0061,  0.0066, -0.0019,  ..., -0.0057, -0.0018,  0.0047],\n",
      "        [ 0.0003,  0.0077, -0.0065,  ..., -0.0043, -0.0024,  0.0052]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0071, 0.0077], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.6719, -0.7148]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# creating out model\n",
    "class BoWClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        super(BoWClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(in_features=vocab_size,\n",
    "                               out_features=num_labels)\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)\n",
    "\n",
    "\n",
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        vec[word_to_ix[word]] +=1\n",
    "    return vec.view(1,-1)\n",
    "    \n",
    "\n",
    "def make_target(label, label_to_xi):\n",
    "    return torch.LongTensor([label_to_xi[label]])\n",
    "    \n",
    "\n",
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE).to(device)\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "    \n",
    "\n",
    "with torch.inference_mode():\n",
    "    sample = X_train[0].split(), y_train[0]\n",
    "    bow_vector = make_bow_vector(sample[0], word_to_ix)\n",
    "    log_probs = model(bow_vector.to(device))\n",
    "    print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a82d1e43-6a01-4181-bfe2-dd9fea66aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning interger to labels\n",
    "label_to_ix = {\"spam\" : 0, \"ham\" : 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10794eab-3fec-4701-92c7-7bd3deaaf90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up loss and optimizer \n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizier = torch.optim.SGD(model.parameters(),\n",
    "                           lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aff7ebd0-0fec-4fce-b7ec-00a351ef828c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of X_train: 4457\n",
      "Epoch: 0 | Loss: 0.05953257158398628 | Test Loss: 1.8723973035812378\n",
      "Epoch: 10 | Loss: 0.014506937935948372 | Test Loss: 1.145749568939209\n",
      "Epoch: 20 | Loss: 0.008510512299835682 | Test Loss: 0.9311169385910034\n",
      "Epoch: 30 | Loss: 0.00580280926078558 | Test Loss: 0.8240097165107727\n",
      "Epoch: 40 | Loss: 0.004236295353621244 | Test Loss: 0.7672484517097473\n",
      "Epoch: 50 | Loss: 0.0032528128940612078 | Test Loss: 0.7330217361450195\n",
      "Epoch: 60 | Loss: 0.0026007420383393764 | Test Loss: 0.7093334794044495\n",
      "Epoch: 70 | Loss: 0.002145014703273773 | Test Loss: 0.6915085315704346\n",
      "Epoch: 80 | Loss: 0.0018120075110346079 | Test Loss: 0.6773880124092102\n",
      "Epoch: 90 | Loss: 0.0015600664773955941 | Test Loss: 0.6657783389091492\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "epochs = 100\n",
    "print(f\"The size of X_train: {len(X_train)}\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i in range(len(X_train)):\n",
    "\n",
    "        bow_vec = make_bow_vector(X_train[i].split(), word_to_ix)\n",
    "        target = make_target(y_train[i], label_to_ix)\n",
    "        optimizier.zero_grad()\n",
    "        log_probs = model(bow_vec.to(device))\n",
    "\n",
    "        loss = loss_fn(log_probs, target.to(device))\n",
    "        loss.backward()\n",
    "        optimizier.step()\n",
    "\n",
    "    if epoch%10 == 0:\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for i in range(len(X_test)):\n",
    "                bow_vec = make_bow_vector(X_test[i].split(), word_to_ix)\n",
    "                test_log_probs = model(bow_vec.to(device))\n",
    "                test_target = make_target(y_test[i], label_to_ix)\n",
    "                test_loss = loss_fn(test_log_probs, test_target.to(device))\n",
    "        \n",
    "        print(f\"Epoch: {epoch} | Loss: {loss} | Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67b01546-468f-4904-9d6c-a1221bf5d8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally:\n",
      "Loss: 0.0013815154088661075 | Test Loss: 0.6568889617919922\n",
      "tensor([ 1.0921, -1.0920], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for i in range(len(X_test)):\n",
    "        bow_vec = make_bow_vector(X_test[i].split(), word_to_ix)\n",
    "        test_log_probs = model(bow_vec.to(device))\n",
    "        test_target = make_target(y_test[i], label_to_ix)\n",
    "        test_loss = loss_fn(test_log_probs, test_target.to(device))\n",
    "print(\"Finally:\")\n",
    "print(f\"Loss: {loss} | Test Loss: {test_loss}\")\n",
    "\n",
    "print(next(model.parameters())[:, word_to_ix[\"won\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ca9bef3-d4a1-40fc-b353-de39d8be4d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models\\spam_prediction_model_0.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Create model directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"spam_prediction_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state_dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model.state_dict(),\n",
    "          f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b27a0980-de15-4825-848f-86372fce1076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shobh\\AppData\\Local\\Temp\\ipykernel_11792\\1307679506.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the model\n",
    "# Instantiating a new instance of our model class to load our model\n",
    "loaded_model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n",
    "\n",
    "# Load the saved state_dict for model_0\n",
    "loaded_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7334201b-d8f7-45a6-ac06-5c55444dea11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('linear.weight',\n",
       "               tensor([[-0.2643, -0.1546, -0.4388,  ..., -0.0057, -0.0018,  0.0047],\n",
       "                       [ 0.2707,  0.1689,  0.4304,  ..., -0.0043, -0.0024,  0.0052]],\n",
       "                      device='cuda:0')),\n",
       "              ('linear.bias', tensor([-2.8458,  2.8605], device='cuda:0'))]),\n",
       " OrderedDict([('linear.weight',\n",
       "               tensor([[-0.2643, -0.1546, -0.4388,  ..., -0.0057, -0.0018,  0.0047],\n",
       "                       [ 0.2707,  0.1689,  0.4304,  ..., -0.0043, -0.0024,  0.0052]])),\n",
       "              ('linear.bias', tensor([-2.8458,  2.8605]))]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict() ,loaded_model.state_dict() # The model have been loaded successfully :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff256bc1-055e-4ca1-b91a-29891a8eb29e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
